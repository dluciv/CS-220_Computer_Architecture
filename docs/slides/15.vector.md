<!-- -*- coding: utf-8 -*- -->
<span id="slides-title" hidden>Векторные вычисления</span>
<span id="slides-author" hidden>Луцив Д.В., Кознов Д.В.</span>


Поняния и таксономия
===

- - - - - -

* **Скалярные вычисления** — работа с одновременно с одним операндом
* **Векторные вычисления** — одновременная работа с массивом данных (вектором)

@pause@

Таксономия Майкла Флинна (Michael J. Flynn), Стэндфордский университет, конец 1960-х

* SISD (Single Instruction, Single Data): обычная машина фон-Неймана
* SIMD (Single Instruction, Multiple Data): машина, выполняющая одинаковые операции над множеством данных
* MISD (Multiple Instruction, Single Data): конвейерные ЭВМ (DSP), системы с резервированием
* MIMD (Multiple Instruction, Multiple Data): многопроцессорные системы (также современные многоядерные)

- - - - - -

## SIMD в x86 и x86_64: MMX

Технология MMX (Multimedia Extensions), 1997 г.

В 32-битном центральном процессоре добавилось 8 новых 64-битных регистров `MM0`, … , `MM7`

* Каждый регистр содержал целочисленный вектор. Вектор мог иметь: 8 компонент по 8 бит, 4 компоненты по 16 бит, 2 по 32 бита или одну 64-битную
* Состав вектора определялся текущей операцией над ним:
  * например, можно было сложить 4 16-битных числа в регистре MM0 c 4-мя числами в регистре MM1 за 1 операцию
  * или сложить те же входные данные в в регистре MM0, как два 32-битных числа, с данными в регистре MM1

- - - - - -

## SIMD в x86 и x86_64: дальнейшее развитие

* SSE (Streaming SIMD Extensions), 1999 г.:
  * 8 128-битных регистров `XMM0`, … , `XMM7`
  * возможности как у MMX + работа с 32- и 64-битными числами с плавающей запятой
* SSE2, SSE3, SSE4
  * специальные операции для криптографии
  * специальные операции для декодирования мультимедиа
* AVX (Advanced Vector Extensions) и AVX2 — регистры 256 бит
* AVX-512: 512 бит, 32 регистра

- - - - - -

# 32 512-битных вектора: много ли это?

На первый взгляд, не очень много. Но… Примеры:

* современное аудио — 16 бит/канал
  * *Одна операция* может обрабатывать 32 значения одновременно
  * В процессоре 32 регистра — меньше обмена данными с ОЗУ
  * **Ускорение в 32 раза**
* криптография строится на арифметике большой разрядности;типичная разрядность операций — 4096 бит; это 8 регистров AVX-512
  * Те же 4096 бит — 64 64-битных числа (в регистрах или ОЗУ)
  * Данные 8 регистров AVX-512 обрабатываются за 8 операций, 64 регистра — за 64 (+ подгрузка из ОЗУ)
  * **Ускорение в 8 раз**

= = = = = =

# GPU и GPGPU

- - - - - -

## Устройство и возможность

* **GPU** (Graphical Processing Unit) — устройство, которое аппаратно реализует частые для компьютерной графики векторные операции
* **GPGPU** (General Purpose GPU) — Возможность использовать GPU для произвольных векторных вычислений, не связанных с графикой, выводимой на монитор и с графикой вообще

- - - - - -

## Исполнение GPU

* *Встроенные (ibtegrated)* — интеграция в CPU (быстрее обмен данными для мелких операций)
* *Отдельные (discrete)* — в составе отдельного видеоадаптера (мощнее)

- - - - - -

<div style="text-align: center;">

![image](images/15.GPU.png) <!--.element: style="width: 70%;" -->
</div>

* Ядер от нескольких десятков до нескольких сотен
* Каждое ядро — SIMD-вычислитель, размерность векторов — от нескольких десятков до нескольких сотен
* Общее большое ОЗУ + маленькое и быстрое у каждого ядра

= = = = = =

# GPGPU-программирование

- - - - - -

## Языки и технологии

Обычно используется диалект языка C
* CUDA — специфичный программный фреймворк для GPU NVidia
* OpenCL — открытый стандарт, обобщающий программирование GPU, многоядерных процессоров и специализированных векторных вычислителей

- - - - - -

## Пример I: сложение массивов

```
__kernel void vector_add(__global const float *x, 
                         __global const float *y, 
                         __global float *restrict z)
{
    // get index of the work item
    int index = get_global_id(0);

    // add the vector elements
    z[index] = x[index] + y[index];
}
```

* *Что это за код?* Исходный код с использованием технологии OpenCL. Функция из примера вызывается для каждого элемента входных данных
* *Где выполняется эта функция?* На GPU; предварительно она компилируется компилятором OpenCL в машинный код GPU (обычно не фон-Нейманновский VLIW)
* *Что делает эта функция?*
  * Работает с данными общего ОЗУ
  * Выясняет у системы требуемый индекс в массиве входных данных
  * Выполняет сложение
* *Даст ли преимущество такая функция?* Если просто складывать два числа, выгоды не будет — данные долго будут загружаться в GPU, вычисления будут долго запускаться. Но для сложных вычислений даст

- - - - - -

## Пример II: проблемы параллелизма

```
__kernel void some_operation(__global const float *x, 
                             __global const float *y, 
                             __global float *restrict z)
{
    int index = get_global_id(0);

    if(x[index] >= 0.0)
        z[index] = sqrt(x[index]) * y[index];
    else
        z[index] = sin(x[index])  + y[index];
}
```

* *В общем случае*
  * Вычисляется условие
  * Над подходящими индексами выполняется ветвь then
  * Над остальными индексами выполняется ветвь else
  * **И всё это последовательно!**
* *Почему это происходит?* Потому что каждое ядро — SIMD-вычислитель, а SIMD одновременно разные операции не выполняет
* *Как этого избежать?* Располагать данные так, чтобы условия внутри одного ядра имели одинаковые значения Меньше пользоваться условными операторами


= = = = = =

### Вопросы

* Что такое таксономия Флинна? Какие модели параллельных вычислений она описывает?
* Что такое векторные и скалярные вычисления?
* Что такое GPU и GPGPU?
* В чём преимущества и недостатки встроенных и отдельных GPU?
* Опишите модель программирования дла GPGPU
* Опишите трудности при программировании GPGPU

### Упражнения

* Поэкспериментируйте с реализацией OpenCL для любого языка программирования (C/C++, Python, Java, С\#, ...)
